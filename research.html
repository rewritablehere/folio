<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>MyPortfolio - Research</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=https://fonts.googleapis.com/css?family=Inconsolata:400,500,600,700|Raleway:400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/line-awesome/css/line-awesome.min.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

</head>

<body>

  <!-- ======= Navbar ======= -->
  <div class="collapse navbar-collapse custom-navmenu" id="main-navbar">
    <div class="container py-2 py-md-5">
      <div class="row align-items-start">
        <div class="col-md-2">
          <ul class="custom-menu">
            <li class="active"><a href="index.html">Home</a></li>
            <li><a href="a_chickanayakanahalli_cv.pdf">My CV</a></li>
            <li><a href="a_chickanayakanahalli.pdf">My Projects</a></li>
            <li><a href="https://in.linkedin.com/in/anantha-cp-57957b13">Linked In</a></li>
            <li><a href="https://medium.com/@rewritablehere">Medium</a></li>
            <li><a href="https://twitter.com/rewritablehere">Twitter</a></li>
            <li><a href="https://www.behance.net/ananthacp685a">Behance</a></li>
          </ul>
        </div>
        <div class="col-md-6 d-none d-md-block  mr-auto">
          <div class="tweet d-flex">
            <span class="icofont-twitter text-white mt-2 mr-3"></span>
            <div>
              <p><em>I love data, graphics, language and problem solving.</em></p>
            </div>
          </div>
        </div>
        <div class="col-md-4 d-none d-md-block">
          <h3>Drop me a note here</h3>
          <p><a href="#">ananthac@ocadu.ca</a></p>
        </div>
      </div>

    </div>
  </div>

  <nav class="navbar navbar-light custom-navbar">
    <div class="container">
      <a class="navbar-brand" href="index.html">MyPortfolio.</a>

      <a href="#" class="burger" data-toggle="collapse" data-target="#main-navbar">
        <span></span>
      </a>

    </div>
  </nav>

  <main id="main">

    <section class="section">
      <div class="container">
        <div class="row mb-4 align-items-center">
          <div class="col-md-12" data-aos="fade-up">
            <h2>Research</h2>
            <p>Graphical framework for defining Context(s) to Virtual Assistants</p>
            <p>#ContextDetermination #ArtificialGeneralIntelligence</p>
          </div>
        </div>
      </div>

      <div class="site-section pb-0">
        <div class="container">
          <div class="row align-items-stretch">
            <div class="col-sm-8 ml-auto" data-aos="fade-up" data-aos-delay="100">
              <h3 class="h3">Abstract</h3>         
                <p> When we have a conversation with a Virutal assistant, there is a theme that is extracted, a context determined from the conversation and a sentiment decoded.
                Data is worked in appropriate models to arrive at key (indicative) information. 
                  What can be determined could be one of many contexts inflected in the conversation.
                  The context in a conversation can be very likely multilayered and multifacetted.
                  A graphical framework may help define to Virtual Assistants these contexts present in the conversation.
              </p><br>
              <h3 class="h3">Background</h3>  
              <p>At the most fundamental level, Machine learning involves splitting data into groups. 
                Deep reinforcement learning procedures demand large amounts of training data.
                For solution to any machine learning problem, we identify the error and go about minimizing the error [1].
                
                Natural Language Processing has enabled virtual assistants to have sophisticated conversations with human beings and respond in context [2]. 
                This is possible by having huge datasets and successive transfer learning cycles passed into the machine learning algorithm. 
                This training enables the system to predict the result required. 
                </p>
              <p>
                Since our contexts are not straightforward and objective, it needs to be translated into a different form before it can be fed to Virtual assistants.
                What defines contexts for human beings could be transalted as boundaries for the assistant to navigate in. 
                By giving the Virtual assistant access to a working knowledge of each facet of a conversation's context, 
                it could be that much more accurate in its replies being inline with the background of the conversation.
                A good way to go about this is to capture the above as an input-output model [4].
                This working knowledge can be provided in a graphical way representing each component of the context by an element in the graphic layout.
               </p>  
               <p>Consider a conversation between the assistant and a human being.
                Suppose a conceptual landscape can be visualised for this conversation. 
                Subject(s) and object(s) and every construct or element in the conversation become physical points in this landscape. 
                Additionally everything that can inflect into the meaning of the conversation, including say, the physical environment of where the conversation is happenning translates into an attribute the landscape. 
                Let us try and demarkate quadrants.
                Suppose we have one side representing the beginning state of a conversation. 
                The end state could be associated to the opposite quadrant. 
                In many cases the conversation will probably not have a beginning and an end state(s) but rather they coincide in the landscape.
                But many conversations will contain an unique starting point and an end point in the landscape that best defines the conversation.
              
                </p>  
               <p>It could very well be many connected landscape areas as there could be multiple contexts.
                But for arriving at something concrete initially we can look at simple conversation where the landcape is a single overall entity and everything considerable and shouldn't be missed is present in it.
                Could the inflection of a string of words in the conversation point to a direction in the landscape described earlier? 
                Can the inflection of the words or the sentence be translated to a journey of subject(s) and object(s) across this landscape?
                
                </p>  
               <p>Consider defining the conversation graphically as system of spaces and vectors. 
                There could be bounds defined in the conversation from what's derivable as subject(s) and objects(s) and their current states.
                A vector has both the magnitude as well as direction. This could be used to identify what tilts it and towards which quadrant. 
                For simplicity all of this can be attempted in a 2 dimensional space.
                </p><br>
              
             <h3 class="h3">Method</h3>  

<p>Start with the simplest conversation possible (minimal or no grammar function, semantically correct). Visualize it using a basic shape in 2d space. In higher dimensions, the same elements can be represented by orbitals in the space.
</p><p>Morphology (how words are formed, their relationship to other words in the same language, the structure of words, parts of words, such as stems, root words, prefixes, and suffixes)
</p><p>We could also look at actual user study data where visual and verbal cues helped persons with cognitive disabilities successfully complete a chosen task [7] This will give us a peek into frameworks that hold concepts.

              <h3 class="h3">Research Questions</h3>  
              <p>Can we arrive at objective definitions of contexts? <br>
                Can a single small conversation be vetted out in this model of representation so that all possibilities and shortcomings of the representation can be identified? <br>
                Can we look at finding invariants in different conversations so that we can arrive at a topological map of this framework
              </p><br>
             
              <h3 class="h3">References</h3>
              <p> [1] https://www.lexalytics.com/lexablog/context-analysis-nlp <br>
[2] Google Duplex: https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html <br>
[3] Event Perception: A Mind/Brain Perspective: Jeffrey M. Zacks, Nicole K. Speer, Khena M. Swallow, Todd S. Braver, and Jeremy R. Reynolds <br>
[4] Joint Cognitive Systems: Foundations of Cognitive Systems Engineering by Erik Hollnagel, David D. Woods <br>
[5] Open Challenges in Modeling, Analysis and Synthesis of Human Behaviour in Human-Human and Human-Machine Interactions: Vinciarelli, et al., 2014 <br>
[6]A Structured Vector Space Model for Word Meaning in Context: Erk and Pado, 2008 <br>
[7] Assistive Technology For Persons With Cognitive Disabilities - Artifacts Of Distributed Cognition (Stefan Carmien, 2006) <br>

[8] Ulrika Wiss, David Carr. A Cognitive Classification Framework for 3-Dimensional Information Visualization <br>

[9] Suchman, L.A., Plans and Situated Actions. 1987, Cambridge, UK: Cambridge University Press. <br>
              </p>
            </div>
          </div>
        </div>
    </section>

    <!-- ======= Testimonials Section ======= -->
    <section class="section pt-0">
      <div class="container">

        
      </div>
    </section><!-- End Testimonials Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer class="footer" role="contentinfo">
    <div class="container">
      <div class="row">
        <div class="col-sm-6">
          <p class="mb-1">&copy; Copyright Anantha Chickanayakanahalli. All Rights Reserved</p>
          <div class="credits">
  
            Built with <a href="https://bootstrapmade.com/">BootstrapMade</a>
          </div>
        </div>
        <div class="col-sm-6 social text-md-right">
          <a href="#"><span class="icofont-twitter"></span></a>
          <a href="#"><span class="icofont-facebook"></span></a>
          <a href="#"><span class="icofont-dribbble"></span></a>
          <a href="#"><span class="icofont-behance"></span></a>
        </div>
      </div>
    </div>
  </footer>

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
